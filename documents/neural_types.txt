ANNs have evolved into a broad family of techniques that have advanced the state of the art across multiple domains. The simplest types have one or more static components, including number of units, number of layers, unit weights and topology. Dynamic types allow one or more of these to evolve via learning. The latter are much more complicated, but can shorten learning periods and produce better results. Some types allow/require learning to be "supervised" by the operator, while others operate independently. Some types operate purely in hardware, while others are purely software and run on general purpose computers.
Some of the main breakthroughs include: convolutional neural networks that have proven particularly successful in processing visual and other two-dimensional data;[82][83] long short-term memory avoid the vanishing gradient problem[84] and can handle signals that have a mix of low and high frequency components aiding large-vocabulary speech recognition,[85][86] text-to-speech synthesis,[87][15][88] and photo-real talking heads;[89] competitive networks such as generative adversarial networks in which multiple networks (of varying structure) compete with each other, on tasks such as winning a game[90] or on deceiving the opponent about the authenticity of an input.[91]
Neural architecture search (NAS) uses machine learning to automate ANN design. Various approaches to NAS have designed networks that compare well with hand-designed systems. The basic search algorithm is to propose a candidate model, evaluate it against a dataset and use the results as feedback to teach the NAS network.[92] Available systems include AutoML and AutoKeras.[93]
Design issues include deciding the number, type and connectedness of network layers, as well as the size of each and the connection type (full, pooling, ...).
Hyperparameters must also be defined as part of the design (they are not learned), governing matters such as how many neurons are in each layer, learning rate, step, stride, depth, receptive field and padding (for CNNs), etc.[94]
Using Artificial neural networks requires an understanding of their characteristics.
Choice of model: This depends on the data representation and the application. Overly complex models are slow learning.
Learning algorithm: Numerous trade-offs exist between learning algorithms. Almost any algorithm will work well with the correct hyperparameters for training on a particular data set. However, selecting and tuning an algorithm for training on unseen data requires significant experimentation.
Robustness: If the model, cost function and learning algorithm are selected appropriately, the resulting ANN can become robust.
ANN capabilities fall within the following broad categories:[citation needed]
Function approximation, or regression analysis, including time series prediction, fitness approximation and modeling.
Classification, including pattern and sequence recognition, novelty detection and sequential decision making.[95]
Data processing, including filtering, clustering, blind source separation and compression.
Robotics, including directing manipulators and prostheses.
Because of their ability to reproduce and model nonlinear processes, artificial neural networks have found applications in many disciplines. Application areas include system identification and control (vehicle control, trajectory prediction,[96] process control, natural resource management), quantum chemistry,[97] general game playing,[98] pattern recognition (radar systems, face identification, signal classification,[99] 3D reconstruction,[100] object recognition and more), sensor data analysis,[101] sequence recognition (gesture, speech, handwritten and printed text recognition[102]), medical diagnosis, finance[103] (e.g. automated trading systems), data mining, visualization, machine translation, social network filtering[104] and e-mail spam filtering. ANNs have been used to diagnose several types of cancers[105][106] and to distinguish highly invasive cancer cell lines from less invasive lines using only cell shape information.[107][108]
ANNs have been used to accelerate reliability analysis of infrastructures subject to natural disasters[109][110] and to predict foundation settlements.[111] ANNs have also been used for building black-box models in geoscience: hydrology,[112][113] ocean modelling and coastal engineering,[114][115] and geomorphology.[116] ANNs have been employed in cybersecurity, with the objective to discriminate between legitimate activities and malicious ones. For example, machine learning has been used for classifying Android malware,[117] for identifying domains belonging to threat actors and for detecting URLs posing a security risk.[118] Research is underway on ANN systems designed for penetration testing, for detecting botnets,[119] credit cards frauds[120] and network intrusions.
ANNs have been proposed as a tool to solve partial differential equations in physics[121][122][123] and simulate the properties of many-body open quantum systems.[124][125][126][127] In brain research ANNs have studied short-term behavior of individual neurons,[128] the dynamics of neural circuitry arise from interactions between individual neurons and how behavior can arise from abstract neural modules that represent complete subsystems. Studies considered long-and short-term plasticity of neural systems and their relation to learning and memory from the individual neuron to the system level.
